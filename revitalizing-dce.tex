% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\usepackage{array}
\usepackage{tikz}
\usepackage{color}
\usepackage{hyperref}
%\usepackage{xcolor}
\usepackage{listings}
\newcommand{\subparagraph}{}
%\usepackage{titlesec}

\lstdefinestyle{CStyle}{
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=C
}

\setcounter{secnumdepth}{4}

%\titleformat{\paragraph}
%{\normalfont\normalsize}{\theparagraph}{1em}{}

\begin{document}
%
% --- Author Metadata here ---
%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Revitalizing ns-3's Direct Code Execution}

%\titlenote{A full version of this paper is available as
%\textit{Author's Guide to Preparing ACM SIG Proceedings Using
%\LaTeX$2_\epsilon$\ and BibTeX} at
%\texttt{www.acm.org/eaddress.htm}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{2} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Parth Pratim Chatterjee\\
       \affaddr{Kalinga Institute of Industrial Technology}\\
       \email{parth27official@gmail.com}
\alignauthor
Thomas R. Henderson\\
       \affaddr{University of Washington}\\
       \email{tomhend@u.washington.edu}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.

% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
%  * What was done? 
This paper describes the design, implementation and validation
of the ns-3 model of the Licklider Transmission Protocol, the standard
transport protocol used to provide transmission reliability in Delay Tolerant Networks (DTNs).
%  * Why do it? 
DTNs are an emerging field whose principles are used to provide communications 
in extreme and performance-challenged environments, such as spacrecraft,underwater, or
disaster response scenarios. Evaluation of such environments requires the use of simulation tools.
As of now, there is a lack of precise simulation models of these protocols, and concretely within the ns-3 simulator.
%  * What were the results?
The ns-3 model presented in this paper accurately models the LTP protocol and offers ...
\end{abstract}

% A category with the (minimum) three required fields
%\category{C.2.2}{ Computer-Communication Networks }{Network Protocols} [Protocol architecture]
%A category including the fourth, optional field follows...
%\category{I.6.5}{ Simulation and Modeling }{ Model Development}

%\terms{Theory}

\keywords{ns-3}

\section{Introduction}

\begin{itemize}
\item Introduce ns-3
\item Motivation of DCE: make complex network implementations available to ns-3
\item History of DCE, and challenge of maintaining it
\end{itemize}
% https://www.theregister.com/2020/01/06/linux_2020_kernel_systemd_code/
% estimated 27.8 million lines of code with 75,000-80,000 commits per year.

The rest of this paper is organized as follows: Section 2 provides an overview on the technical challenges due to Linux evolution.
Section 3 describes solutions.
Section 4 presents the results.  Section 5 related work.  Section 6 conclusions
and future work.

\section{Challenges}

\subsection{libio vtable mangling}
The vtable is a table maintaining references to functions called for virtual functions defined for a class or an entity. These functions can 
be overriden dynamically by user defined functions and the respective call for the corresponding virtual function in a derived class object can be bound 
to that function at runtime, unlike pre-defined functions which are static, fixed, and can be determined during compile time. The libc on Linux provides
this highly flexible feature for most user defined classes, but the case with the FILE structure is not the same.

The FILE structure is a library defined structure which defines the overall organization, orientation and properties of any file I/O stream opened
by the host application. It maintains different parameters for storing useful operational fields like the UNIX based file descriptor number of the 
opened stream, the read/write offsets and buffer addresses of the stream. The pseudoname for the FILE structure as seen inside libc is \textit{\_IO\_FILE}. 
Since, FILE is a library defined entity, the library provides its own set of implementation for all possible operations on an open FILE stream.
Whenever an \textit{\_IO\_FILE} stream is allocated by the kernel, a contiguous memory location is allocated as a block called \textit{\_IO\_FILE\_plus}. 
The \textit{\_IO\_FILE\_plus} structure looks like this.

\begin{lstlisting}[style=CStyle]     
struct _IO_FILE_plus
{
  FILE file;
  const struct _IO_jump_t *vtable;
};
\end{lstlisting}

By nature of the implementation of the kernel's memory allocation processes, the contents of a struct are allocated in contiguous memoory locations. 
This can be verified by the \textit{sizeof} operation of C showing that the sum of sizes of the individual members of a struct is equal to the size of
the struct object. Similarly, the FILE and the \textit{\_IO\_jump\_t} objects are allocated in contiguous memory locations. Specifically, the 
\textit{\_IO\_jump\_t} areas is interesting to DCE, as it defines the callbacks or reference pointers to the functions handlers for each supported file 
operation. Some of the callbacks which are interesting to DCE and its use cases are highlighed below.

\begin{lstlisting}[style=CStyle]     
struct _IO_jump_t
{
...
ssize_t(*) __read (FILE *, void *, ssize_t);
ssize_t(*) __write (FILE *, const void *, ssize_t);
off64_t (*) __seek (FILE *, off64_t, int);
int (*) __close (FILE *);
int (*) __stat (FILE *, void *);
...
};
\end{lstlisting}

This structure acts like the vtable for the FILE structure, but it does not behave like the oridinary vtable seen when working with virtual functions 
and derived classes, which are dynamic and supports run time bindings. This vtable is instead expected to behave as a statically bound vtable.  There exist 
other libc functions, like \textit{fopencookie}, to override some of the FILE operation implementations, but not all operations are supported, and 
\textit{fopencookie} also does not attach itself to a standard file I/O stream, 
instead working with user defined buffers a.k.a cookies). 

A key aspect of DCE is that it needs to \textit{hijack}
application operations like system calls, file I/O operations, and networking
system calls, and re-route them through 
corresponding handlers based on the application logic and simulation script implementation. Considering file I/O operations, DCE needs to have control 
over read/write/close/seek/stat operations of each open file, which requires
overwriting the vtable handlers with the corresponding handlers defined 
in DCE's stdio definition source files. 

Taking advantage of the contiguous memory allocation of the FILE and \textit{\_IO\_jump\_t}, one can overwrite the vtable with a custom vtable definition for all the operations needed for DCE. One can make a dummy \textit{\_IO\_FILE\_plus} 
pointer point to the explicitly casted FILE object. \textit{memcpy} the existing vtable to a local copy, modify and overwrite the stream operations with a 
custom written implementation, and then re-point the vtable field of the dummy \textit{\_IO\_FILE\_plus} to the local modified vtable.  This allows
control over stream operations, which can now be routed through and and to behave as ns-3 streams, Unix FD streams, etc. based on the type of file 
descriptor that is defined.  Although this control over FILE streams
to regulate stream buffer flushing and data redirection is productive for
DCE, these techniques can also be used maliciously for
\textit{buffer overflow attacks}, as it lets penetration 
testers to make use of tools like pwntools etc. to gain control over application execution and important run time CPU register values such as the 
\textit{rip} which is used for the relative addressing of application components(which is also how position-independent-executables work), which is more 
secure as compared to static addressing, where fixed address values of symbols and pointers could be gained by static analysis tools for run 
time application exploitations.

Post libc-2.25, security features have been implemented to glibc to identify 
and block buffer overflow attacks on the FILE object. Whenever any FILE
operation is executed, glibc 
verifies if the FILE object's vtable can be trusted and is not corruputed or manipulated. To verify this, it makes a call to 
\textit{\_IO\_validate\_vtable}. Every libio vtable is defined in a unique section called \textit{libio\_IO\_vtables}. By definition, libc trusts
the vtable if the vtable of the current FILE object lies within this section. It checks if the offsets of this vtable lies between 
\textit{\_\_stop\_\_\_libc\_IO\_vtables} and \textit{\_\_start\_\_\_libc\_IO\_vtables}, if it does, we can continue with the operation, if not, libc 
conducts a final check by calling \textit{\_IO\_vtable\_check} which makes final checks on the FILE vtable pointer location, namespace and edge cases
where FILE * objects are passed to threads which are not in the currently linked executable.  When DCE overflows the \textit{\_IO\_FILE\_plus} and 
overwrites the \textit{\_IO\_jump\_t}, it does not lie in \textit{libio\_IO\_vtables} section and it also does not pass the pointer mangling sanity checks, leading to a \textit{\_\_libc\_fatal (\"Fatal error: glibc detected an invalid stdio handle\");}

\subsection{PIE loading and usage}
PIE or position-independent-executables are applications compiled with special compiler flags, which allow the application to be loaded into random 
memory address, not depending on absolute symbol addresses, avoiding exploits which hijack the call stack by referencing constant function/symbol addresses.
In the case of a PIE, every memory address is accessed with refference to what is called the \textit{\%rip}. The \textit{\%rip} is computed at the time 
of execution when the application is loaded into virtual memory. This makes it difficult for attackers to determine symbol location in memory.

In DCE, we support the execution of real host application in simulation, bridging the networking layer between the host and the specified networking stack,
and also other system calls made by the host applications. Since, we might have to load several applications into memory, and alsp have control over the
position of the \text{main} symbol of the loaded application, we need to have position independent executables, so that when they are loaded into memory,
the symbol positions in memory are dynamic, giving us control over when an application is launched in a simulation which can be configured in the script 
using available ns-3 programming constructs for the \textit{DceApplicationManager} class. To implement this, DCE used the \textit{CoojaLoader} which 
uses dlmopen udner the hood to load the executable into memory. In glibc version newer than 2.25, security checks have been introduced to identify such 
PIE objects being loaded through dlmopen, and in case it finds the \textbf{DF\_1\_PIE} flag in it's ELF Dynamic headers, if would abort with an error.


\subsection{Linux Networking Stack for DCE}
DCE is by nature of ns-3 designed for writing network simulations and achieve real world like results. It makes is necessary for it to provide script 
writers with freedom to choose which networking stack they would want to make use of for their simulation script. We currently support the following 
networking stacks : Linux, ns-3 and FreeeBSD. Script writers can configure the \textit{DceManager} class by setting the network stack to what they preffer.
Currenly, the Linux network stack is based on net-next-nuse-4.4.0, which is built on top of base Linux kernel version 4.4.0. net-next-nuse is a library 
port of the Linux kernel, which does selective linking of requried kernel modules and components such as the networking, VFS, MMU, etc. layers, patching 
the holes with glue code, exporting DCE useful callback structures, abstracting the internal network data flow, also syncing Linux kernel synchronization, 
process creating, and DCE-kernel task, IRQ and tasklet scheduling and synchronization, to expose a Linux like execution bed for host applications. 

Since Linux kernel 4.4.0, the later Linux kernel releases have had major developements in almost all kernel compoenents, but for our specific use case
the networing stack has seen major changes in several components such as the TCP Timer, Jiffies and clock HZ usage, napi working and internal enums 
and state definitions and checks, Packet flow, checksum and offloading hardennings, newer congestion control algorithms, ucounts API, etc. 
The current Linux kernel networking stack does suffice for now, but hasn't kept pace with the current research needs. 

\subsubsection{LKL}
LKL also known as Linux Kernel Library, is a library port of the Linux kernel which through some pre-shipped helper shell scripts can be used to hijack
all system calls made by the host application and map it through the ported Linux kernel rather than system defined implementations. It also allows one 
to setup network interfaces such as TAP, RAW, VDE , etc. with custom gateways, masks, IPs, etc. with the help of json configuration files. These helper
shell scripts make use of LD\_PRELOAD to reorder library loading to LKL written system calls to take control in place of the libc defined routines.

\subsubsection{LibOS}
LibOS can also be reffered to what internal architecture net-next-nuse uses under the hood. It is also a Lixnu kernel port which works on selective 
kernel module linking and patching on the go working princinple. It defines special link time constructs to include only specific kernel files and 
symbols which are needed for executing on top of the Linux kernel with \textit{nuse}, which works similar to LKL in terms of hijacking system calls 
and rerouting them through nuse and kernel defined routines. It only links kernel components which lets LibOS start the kernel and run all \textit{\_\_initcall}(s)
which are defined with a \textit{\_\_init} and registered as as a initcall using special macros. Thes routines are linked into special \textit{.INIT} 
setions of the final linked library. These components include critical parts such \textit{kernel}, \textit{net} and other selective parts of \textit{proc},
\textit{mm}, \textit{fs} , \textit{drivers}, etc. 

\subsubsection{LKL vs. LibOS}
Below is a parameter wise comparison of LKL and LibOS on the various design decisions which become critical for a complex application framework like 
DCE with very specific demands from it's underying network stack.

\paragraph{Linux Kernel Support}
LKL, which was primarily designed to work as Linux-as-Library interface for application to be dynamically linked to at runtime, is built on top of 
Linux 5.2. The kernel port design of LKL, favours kernel version upgradation with little to no efforts. Abstractly, the kernel upgradation process 
would include a git rebase on the kernel version we would want to use, and project should compile with no major issues to deal with (some minor compiler, 
and Linux kernel header definition changes might come up, which should be resolvable with a bit of effors).

LibOS, which makes use of dynamic selective Linux kernel linking, bridges the gap between application workspace and Linux kernel networking stack with
the help of glue code, kernel component connector code, and user application provided exported functions and callbacks for proper execution. This
architecture required LibOS to modify some of the internal Linux kernel files for additional compoenets such as the slab allocator, which requires 
LibOS to setup preprocessor directives to select out SLAB allocator for specific Kconfig defined compiler directive, to pass on control to LibOS routines 
whenever required. Currenly LibOS supports Linux kernel 4.4.0. Upgrading to a newer Linux kernel version might be an intense process requiring one 
to deal with issues from header file changes, to complete changes in kernel components like the networking layer, memory maqnagement, namespace manager 
and kernel boot process.


\paragraph{In-Library Kernel Boot Order}
Apart from certain functionalities which are initialized only in a user OS such as HW drivers and devices,
such as network buses, NICs, etc. LKL spins up an LKL high level CPU lock controlled thread, which makes calls to 
start\_kernel. LKL being an uniprocessor system, initializes kernel on a singular LKL thread, locks of 
which are synced with Linux scheduler calls, which are called when the scheduler decides to switch execution control 
to kernel level tasks for preemption, and other tasks, which require certain memory level moderation to achieve
atomic operation. Also, since the LKL CPU thread needs to be initialized before any linux  functionalities can be use by the 
application thats using the LKL library, it eventually disrupts the flow of DCE scripts, which works on a 
scheduling algorithm, which works on specific ns-3 task context switch paradigms, different from the Linux kernel,
making it wait for LKL's internal Linux kernel opertions to finish, before it can schedule other ns-3 Light weight
threads, making simulation results differ a lot from real world observations.

LibOS, does not depend on the actual start\_kernel, particularly because as opposed to LKL which sets up an environment 
for the Linux kernel all the basic requirements for the kernel to assume an actual linux workspace making it easy 
for LKL to access most of Linux functionalities without any change to kernel internals, LibOS on the other hand makes 
use of it's own lib\_init fuction which calls specific setups calls required by the network stack of the kernel to 
work, such as proc, VFS, ramfs, scheduler, etc. It also overrrides scheduler member functions, syncing it with ns-3 
scheduler's. LibOS creates an ns-3 task copy for each kernel task which is created by the copy\_process, create\_process,
etc. kernel functions. Each such task maps with itself a callback function which should be called once the wait time
for a task is over, or has been invoked as a part of a regular scheduling process. Once tasks are processed, it is
also popped off the ns-3 task queue.
\paragraph{Maintenance}
LKL, was designed to be a low maintenace Linux-As-A-Library interface, which exposes Linux subsystems through overided UNIX system calls. 
Since, LKL is an architecture level port of the Linux kernel, isolating LKL specific code to the arch and tools Linux folders, moving on to 
newer or custom releases induces less cost as compared to LibOS, which works on dynamic component compiling \& linking build system through a
custom Makefile, where are Linux files and modules to be compiled and linked to the final nuse shared object file, should be explicitly mentioned,
and this listing should be exhaustive, assuring no function calls are being made by any critical component to another component which does not 
exist, and if it does, we need to fullfill the depedency graph for all such modules and file. This makes migrating to newer versions of Linux kernel,
or for that matter, simply debugging kernel internals, requires more effort as one is not sure if it's the glue code that's malfunctioning, or is it
the allocator or the ns-3 synced scheduler causing trouble.

\section{Solutions}
\label{section:design}

\subsection{Custom glibc-2.31 Based Build}
On a Linux environements, multiple library systems could be selected to be linked to. A few options are libc are musl. The post-linking structure
of the generated binary and the libary vary, in terms of the number of static linkages, symbol table, etc. For instance, musl works on the idea of
single static linkage, in which, the library or executable compiled with musl-gcc, is statically linked to only one musl linked library called 
ld-musl.so.1, which defines all the symbols required by the application. This reduces the size of the executable to a huge extent, but 
also does more harm than good to DCE. The initial build step of DCE includes calling a script named dcemakeversion.c. This script is responsible 
for extracting the symbol table of the libc currently being linked to. All symbols for the libraries libc, libpthread, librt, lib and libdl. These 
libraries are the various modular extensions of the glibc providing features such as pthreads, math, dynamic library loading and the base libc 
library as well. The symbols are read from the Elf Headers of the respective shared library .so file, and stored in a local .version .

The symbol table for all these libraries are important for us, as DCE as a build outout generates what is called the libc-ns3.so. This is a shared 
library which is a wrapper for the local libc and DCE implementations, on top of which host applications are executed. This shared library defines 
all symbols which are defined in the local libc, as NATIVE and all the features implemented inside DCE as DCE. All other symbols which are new to 
DCE and not implemented by us, but is a part of the local system libc, is then refferenced in the .version files. These symbols are then defined 
as well, to avoid any runtime symbol lookup errors. It then generates preprocessor mappings for all the symbols. All DCE defined symbols will 
natively be mapped to DCE implemented versions of them, rather than the systel libc implementation, and all NATIVE defined symbols will be mapped 
to global namespace implementations, which are the ones already implemented in the system libc. Users would compile their applications on top of 
the system libc itself, but with an extra -fPIC and -pie flag, which allows us to load the applications dynamically into out process address 
space. We then load out libc-ns3.so shared object file, and call out libc\_setup function which initialiazes the system call mappings. We also 
subsequently load other libraries which we have generated in a similar way, i.e, libpthread-ns3.so , librt-ns3.so , libm-ns3.so and libdl-ns3.so .
We then finally load the host application, lookup and call the main function of the application, which starts to now work on top of our custom 
libraries. musl-gcc on the other hand does not support modular libraries for these features, and for all cases would link the single ld-musl.so.1, making it 
impossible for use to seggregate the symbols for all our different libraries. glibc, on the other hand, works exactly how we would want the standard 
library to, and links all the standard libraries we require.

In an attempt to override the vtable mangling security checks, it was necessary to use a libc version that matches the system default libc version 
so that we dont see any symbol lookup errors at runtime because of application built on later libc release and beig loaded into an available namespace
using dlmopen. But, we also had to override the security checks on vtable pointer mangling. The gcc compiler and linker options could be used to 
reconfigure the default build environment to build DCE on top of a custom built patched glibc. The default root directory where gcc starts to look for
libraries, header files, etc. is  '/' on Linux. We need to re-point this directory to out customg glibc root. This is where the --sysroot option 
is used to set it to correct bake build directory. We then add the custom glibc prioritized directory for library and header file lookup using the 
-L and -I option respectively. We then set the rpath and rpath-link paths for ELF executables that could be linked to the shared objects at run time 
or link time respectively. We then set the dynamic linker to one we have build currently, using the -Wl--dynamic-linker flag. Also, all these changes
are placed under an unclosed -Wl --start-group, as DCE requires other linker flags, which when added we insert the ending -Wl --end-group.



\subsection{Bake Build Automation}

Bake works on a build configuration script called bakconf.xml . The bakeconf.xml file is converted to bakefile.xml after the configuration file is 
parsed by the Bake module. Based on the bakeconf.xml file creates a build Dependency graph, maintaining build steps, parameters and post build 
commmands for each Dependency node. Bake dynamimcallly binds Dependency modules based on configuration options specified for each build module 
defined in the bakeconf.xml. The three mahor steps of a Bake build are, configure, download and build. Bake supports almost all major types of 
source code fetching methods, ranging from git, mercurial to standard publicly available zipped archive files. In the build step, dependencies 
are built in the order with modules having no dependencies on other modules, to the module having all dependencies already satisfied. To support 
the custom glibc build, the dependency graph looked something like this : 

ToDo : Attach Bake Dependency graph ? 

Bake has a source configuration option named patch, which can safely aplly a patch, without re-applying if it has already been applied before.
Using this option, the custom DCE specfic libc patch is applied, which disables the security checks on vtable mangling, and also disables the 
pie object checks for dlmopen position independent executable loading. The glibc is then build using standrd build steps. The linux kernel headers
files are then installed into /usr directory of a custom glibc's sysroot. This leaves with a standard Linux like system root to use for building 
DCE without any issues. 


\subsection{Docker environenment for DCE}

\subsection{net-next-nuse-5.10}
Net-Next-Nuse is an architecture port of the Linux Kernel, which resorts to selective kernel module linking and takes control over critical kernel 
components such as the slab allocator, task scheduler, workqueue-waitqueue handling, timer based function invocation, as well as some kernel 
utilities such as jiffies and random number generators. It also sets up emulations of the network system calls for both general socket networking 
operations as well netdevice based operations. All of this is exposed through an API initialised by a simulator initialisation call, sim\_init, 
which does a bidirectional mapping of the imported(DCE → Linux) and exported(Linux → DCE) function utilities.

\subsubsection{Background}
The implementation of net-next-nuse strictly considers only the use case of DCE and thus might not find application outside of DCE unlike LKL which
is designed for running a plethora of networking applications, but it fits in really well when it comes to DCE. 

When Linux builds, apart from all other files, it generates two important files vmlinuz and initramfs. The file vmlinux is where all the kernel 
code(/kernel /mm /fs /net /security ...) is compiled and linked. When it comes to LKL, it does a raw objcopy on the generated object 
files vmlinux and copies all symbols from vmlinux along with the global functions exported from the LKL arch port, and combines them into a final 
library called lkl.o, which is then passed on to the tools/lkl, to link the host, netdevice, utility, filesystem, and networking handler codes to 
make the final liblkl.so shared library.

net-next-nuse understands that the way Linux Kernel behaves on the host, and the way the kernel interacts with the task 
scheduler and how the scheduler operates on the tasks, is completely different from how DCE manages fibers(called task in DCE terminologies). 
DCE is based on context based light weight threads called fibers, which require a custom scheduler, called TaskManager in DCE. On an ordinary
host machine when you run any application, and then you spin up normal threads, you would not need to bother about scheduling the threads on 
the different cores of your cpu and maintaining mutex locks of the cpu, making the kernel responsible for jumping from one thread to another. 
But when you use fibers, you can jump from one thread to another only when one of the fibers yields to another fiber, and this context switch 
is done by a custom scheduler, which is written in TaskManager::Schedule(). When you use ordinary threads, the number of context switches the 
CPU has to do (push your thread data stack on to you address space, in and out), is a lot more expensive than making switches in Fibers.

We have a scheduler inside DCE, but now when we load a linux kernel library, we also have a scheduler that comes along with it. \
So, every new operation that you make inside the kernel creates something called a (virtual) kernel thread. But manage those threads is seemingly 
difficult because the DCE TaskManager cannot see them as it’s virtual. net-next-nuse does a selective linking of 
kernel modules and utilities and avoids linking of the scheduler, workqueue, waitqueue and other such linked components, and rather implements 
them using DCE imported functions which maps to TaskManager utilities. So everytime some process wants to preempt and block, the kernel calls 
schedule() or schedule\_timeout(), and we pass control to DCE to take care of it. 

\subsubsection{Slib Allocator}
When the kernel is booted up by net-next-nuse in lib\_init(...), it calls some of the required initialisation functions, and all, included, initcalls. 
Most of these initcalls require us to create a memory cache object called kmem\_cache. These memory slabs are used to allocate memory to child 
objects. It uses functions like kmem\_cache\_alloc(...) and functions as simple as kmalloc(...) to allocate space for a pointer object. Now, the 
kernel already has slab allocators like, SLUB and SLOB, but all of them allocate space internally, giving no control to DCE. We thus use a custom 
SLAB allocator called SLIB, which calls internal DCE malloc(...) functions and sets up kmem\_cache data structures and ctor’s etc. It also 
implements compound and single page operations like \_put\_page(...), kfree(...)  and array space allocation. 

\subsubsection{Virtual Kernel Task and its Real Fiber Equivalent}
Let’s talk a little about how threads are internally managed in the kernel. For every new task inside the kernel, for example, a syscall, 
creates an internal kernel thread. Now originally when a system boots up, there has to be some initial task that invokes the start\_kernel(...) 
function. This is called the init\_task. Whenever a new kernel thread is to be created, we make a call to kernel\_thread(...). Along with the 
function that is to be invoked in the thread, and the arguments to be passed, we also need to pass along one more argument, known as clone flags. 
Internally, the kernel will try to clone a previous task (or you can say the init\_task), as much as possible. These flags basically determine 
how far the kernel should go, as in cloning the structures. Some of the flags are CLONE\_FS, CLONE\_VM, CLONE\_FILES, etc. kernel\_clone(...) and 
passes a special clone flags data structure. This function further calls copy\_process(...). copy\_process(...) is responsible for checking which 
flags are enabled using a bitwise \& operator and calling the corresponding copy utility, for example copy\_fs(...), copy\_files(...), copy\_cred(...),
It also makes a call to dup\_task\_struct(...), which will bind changes of the current task\_struct to a new one and return it back. After we get 
back a proper task\_struct, the kernel\_clone(...) schedules a fork for the newly created tNNask.

But the point is, we don’t need most of it ? Why ?  Because it’s irrelevant to us. DCE is not a complete architecture level port and thus lacks a 
clear definition of init\_task. So, for the very first kernel\_thread the current task would be init\_task, so not having a proper definition of it, 
creates a domino effect making all subsequent taks having incomplete structure, leading to possible SEGFAULTS. Another reason is, we do not use 
the kernel scheduler, rather we need to fork a kernel thread in such a way that the DCE scheduler can see it, and every time 
TaskManager::TaskWait(...)  is called on a particular task, we can put the current job to sleep, and give the other tasks/fibers a chance to 
execute their set of functions. 

So, to take  control over the kernel thread creation, we rewrite the kernel\_thread(...) function to call lib\_task\_start(...), which calls the 
internal TaskManager::Start(...) to create a DCE task, fills up the task\_struct, sets the SimTask context with the task\_struct and returns back 
the pid of the task. Also current as previously referred to before, is not a variable. It’s a MACRO, which calls get\_current(...) which we hijack 
and lead to TaskManager::TaskCurrent(...), which checks if the current task has a SimTask context, if it does, it returns it back. 
If it does not, it calls TaskManager::Start(...) to set it up.
 

\subsubsection{Scheduler Workqueue/Waitqueue Implementation}
Most of the scheduling code can be found in the /kernel directory of the Linux Kernel. This is very important to us and so we never compile the 
original kernel implementation for the scheduler. We rather implement all the key functionalities used by the networking stack. So, 
question is, if we are not running any applications inside the kernel, why do we even need to schedule anything ? The answer to this is 
blocking network calls. Imagine you creating a socket, binding and listening to it and then you make an accept(...) call, and the client 
application doesn’t seem to ever come up. The system would go to a standstill if it did not schedule the client application for it to issue a 
corresponding connect(...) call. And that’s one of the issues with LKL [4.2]. That is why we avoid linking those files, and rather pass 
majority of the control to DCE, but without making a single change in code, because DCE also has to work when simulation scripts use the 
default ns-3 network stack. We thus rewrite certain functions. Below a few function and concepts have been discussed : 
schedule() : 
schedule\_timwout() :
lib\_task\_wait() :
lib\_task\_yield() : 
add\_timer() : 
mod\_timer() :
init\_timer\_key() :
do\_softirq() :
open\_softirq() :
queue\_work\_on() :

\subsubsection{Jiffies Timer}
The Linux kernel management of time is based on the use of the global jiffies variable
which contains a 32bit integer that reports the number of ticks elapsed since the boot of
the kernel. The duration of each tick depends on the way the kernel was configured but
nowadays, it is usually configured to be one millisecond. The jiffies variable is normally
increased whenever the kernel timer interrupt is triggered. This timer interrupt is also
responsible for executing any expired kernel timers every ten millisecond, etc.
[22, 19] both deal with this by executing periodically a per-node event that increases
the jiffies variable and relies on the Linux kernel code to deal with its internal timers. This
approach suffers sadly from one major drawback: even if there are no timers scheduled to
expire for the next 10 or 80 milliseconds, the simulation will keep running and executing
events, just for the sake of incrementally increasing the value of this jiffies variable.
Rather than waste time to do this, we instead configure the Linux kernel to not use periodic
ticks with CONFIG NOHZ and then replace entirely the kernel timer facility to schedule
simulation events for each kernel timer instead of keeping track of the kernel events in a
data structure separate from the main simulation event list. The resulting kernel network
stack thus runs in tickless mode and does not waste time scheduling unnecessary events.


\subsubsection{Kernel Initialisation}
The Kernel initialisers are divided into base init functions and roughly 8 levels of initcalls and exports a start and end pointer of the list. 
Init functions are the ones directly called in the start\_kernel(...) or by certain device drivers, whereas initcalls are the ones which are stored 
in a special .initcall.init section of the final linked library. These are then copied to their respective positions through the linker.lds script.
In out lib\_init function I call specific init functions, namely : 
vfs\_caches\_init\_early
rcu\_init
devices\_init 
buses\_init
radix\_tree\_init
timekeeping\_init
cred\_init
uts\_ns\_init 
vfs\_caches\_init 
seq\_file\_init 
proc\_root\_init
I also changed the initcall invocation loop of lib\_init to this : 
\begin{lstlisting}[style=CStyle] 
   initcall_entry_t *call;
   extern initcall_entry_t __initcall_start[], __initcall_end[];
 
   call = __initcall_start;
   do {               
       initcall_from_entry(call)();               
       call++;
   } while (call < __initcall_end);

	Before we call all the init functions, I also added these two lines of code :

   files_cachep = kmem_cache_create("files_cache",
           sizeof(struct files_struct), 0,
           SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,
           NULL);
 
   fs_cachep = kmem_cache_create("fs_cache",
           sizeof(struct fs_struct), 0,
           SLAB_HWCACHE_ALIGN|SLAB_PANIC|SLAB_ACCOUNT,
           NULL);
\end{lstlisting}
	These caches are required while setting up the fs\_struct and files\_struct for each new task in it’s corresponding task\_struct. Please see [5.9].


\subsubsection{Security LSM Module}
The security module of the Linux kernel depends on a special configuration called the CONFIG\_LSM. The LSM module requires a few architecture
defined variables. Surprisingly, you cannot find them in the source code(.c or .h files) anywhere, rather they are placed in a specific section
of the library/binary called .init.data section, through ASM code. net-next-nuse makes use of a linker script which can help us position variables inside
the library under specific sections. I had to put this code in the linker.lds to initialise the start and end of the LSM table.
\begin{lstlisting}[style=CStyle]
  . = ALIGN(CONSTANT (MAXPAGESIZE));
  .init.data : AT(ADDR(.init.data)) {    
		__start_lsm_info = .;	
		KEEP(*(.lsm_info.init))
		__end_lsm_info = .;    
		__start_early_lsm_info = .;	
		KEEP(*(.early_lsm_info.init))
		__end_early_lsm_info = .;
  }
\end{lstlisting}
vfs\_kern\_mount(...) validates and parses params using security\_fs\_context\_parse\_param(...), which checks if the requested operation was blocked
in the LSM tables. If this module is not enabled, it would return back ENOPARAM by default and fail.


\subsubsection{Kernel Code - net-next-nuse Alignment}
I had to remove the panic\_on\_taint symbol, which got exported while linking kernel/panic.c(we need to have this file for acknowledging kernel
runtime errors) and accessing it in kernel/sysctl.c caused errors because it couldn’t find it back. Also, having this made no sense, as its value
defaults to 0 and never changes during program execution. When the kernel gets initialized, it called mnt\_init, which is responsible for setting
up the kernel file system (kernfs), the sysfs, ramfs, etc. and then makes a call to init\_mount\_tree, which sets up the required namespace for the
all the mounts. This function will then make a corresponding call to vfs\_kern\_mount, which will use the vfs setup to initialise the file systems
we need. vfs\_kern\_mount will set up the file context and mount it. In this process it checks for the security module and the LSM entries, to check
if the kernel was not previously configured to avoid declaration of the specified namespace. If all checks pass, it returns back a vfsmount
pointer. We then use this pointer to set up a mount namespace which initialises the data structure mt\_namespace, using alloc\_mnt\_ns . To
initialize the mnt\_namespace object, we require the current tasks nsproxy, which is the user namespace proxy member. Every task is required to
define some initial maximum value for each namespace it might require during the execution of the task. Similarly, for allocating a mount
namespace it increases the UCOUNT\_MNT\_NAMESPACES of the current task’s nsproxy which has an upper bound of init\_task ‘s value. Since, we are not
doing a complete arch port (we don’t need to), this value is not defined, and would through a SEGFAULT, when READ\_ONCE(...) tries to make an
atomic operation on it to access it and increase the value by 1 if doing so doesn’t exceed the max limit, using the atomic\_inc\_below(..)  macro.
We thus manually set the value for it, during task initialisation in lib\_task\_start(...).

\begin{lstlisting}[style=CStyle]
ucounts->ns->ucount_max[UCOUNT_MNT_NAMESPACES] = MNS_MAX;
\end{lstlisting}

But, we did set up the mount namespace, for the init task, but what for the other tasks ? We thus create a global variable def\_mnt\_ns and
store a backup of the first mount namespace using an extern variable and then later on set it up in the lib\_task\_start(...)
\begin{lstlisting}[style=CStyle]
struct nsproxy *ns;
ns->uts_ns = 0;
ns->ipc_ns = 0;
ns->mnt_ns = def_mnt_ns;
ns->pid_ns_for_children = 0;
ns->net_ns = &init_net; // global struct * net   
task->kernel_task.nsproxy = ns;
\end{lstlisting}

This seems good right ? But what  is def\_root ? Ok, I had to hack this again XD.
Remember init\_mount\_tree, we discussed it in the pointer above. What does it do ?  It sets up a vfs mount. Okay, does that mean a path somewhere 
in the kernel ? Yes it should have. I also found another line of code there : 
init\_task.nsproxy->mnt\_ns = ns;

Okay, does this mean that the first task has the mount namespace generated while we mount and allocate the mount tree and acquire an mnt\_namespace. 
What else can we observe here ? How does the Linux Kernel create tasks then ? Do you remember doing these when you create processes on your OS ? 
No, right ? Which means, do we reuse some of the previous data from the init\_task and replicate them in new tasks. Yes, we do. Whenever we create 
a kernel\_thread(..) it calls copy\_process(...) which copies some of the required parameters from the host task, depending upon the flags you pass 
it. For example, If you had set the CLONE\_FS flag, it would copy the fs\_struct from the init\_task to the newly made task, by calling copy\_fs(..)
in kernel/fork.c. Which means, if we never have diverse task member requirements we can just reuse the previous task, implying the first task ?  
Right ! So, we can then just declare a global def\_root and then by declaring an extern variable for it, and keep reusing !

The netif\_napi\_add tests for the NAPI\_STATE\_LISTED bit to be enabled in the state of the napi\_struct passed on to it from cgroup init calls. 
We never set this flag directly, so this check was removed from the kernel code. sock\_init is one of the many initcalls which are called when 
sim\_init is invoked by DCE. First of all before we proceed with anything, it is necessary that we have initialised the proc file system completely,
so that the sysctl interface could be initialised by the net\_sysctl\_init(...). We then register the sockfs filesystem using register\_filesystem(...) 
and go for a kern\_mount(...) which invokes the VFS kern mount function and as discussed above, it requires the mnt\_init(...) to correctly setup 
the mount environment. Initially, in net-next-nuse-4.4.0, mnt\_init(...)  was made a blank function, and we have reasons to support it. 
In older kernel releases, sockfs file system init did not depend on a file system context, and required a mount function (sockfs\_mount) which
would directly mount the file system onto the kernel, but in commit [6.1], the socket file system mounting process was handed over to the
internal VFS mounting mechanism, thus breaking our setup. So, now we need to have the mnt\_init(...) and put in patches and glue codes wherever
needed. ToDo include/arm changes to files, for example, atomic, barrier, ptrace, user, user32/64….
ToDo Rump kernel header file double include, adding flag to disable linux include

\subsubsection{Native Kernel NetDevices}
Certain components of ns-3 require to setup custom NetDevices which require a custom mtu and other flags such as should it be a multicast device,
or a P2P device, or should it broadcast etc. These flags could be put togethers and we can allocate a netdevice for each such requirement using
the alloc\_netdev(...), passing all the configurations needed for mtu,address length, and destructors, along with a register\_netdev(...) call.
This would return back a forward declared struct SimDevice which is (probably)  casted to a NetDevice object inside ns-3.


\begin{itemize}
 \item Requests are provided in the form of API functions ...
 \item Notifications are provided as callback functions ...
\end{itemize}

The LTP may be run at different protocol layers in order to provide support for this
we provide Convergence Layer adapters ...

LTP uses engine IDs as its addressing system, we provide a lookup structure in the form of LTP to IP resolution tables ...


\section{Results}

\subsection{Docker vs Native DCE Simulation Tests}

\subsection{Performance : DCE vs. ns-3}

\subsection{Google BBR v1 Validation Results}

\section{Related Work}

\section{Conclusions}
%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{ltp-ns-3-workshop}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
%\balancecolumns % GM June 2007
% That's all folks!
\end{document}
